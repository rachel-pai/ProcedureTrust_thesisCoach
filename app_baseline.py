# baseline_chat.py
import os
import json
from pathlib import Path
from typing import List, Dict, Any

import numpy as np
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
import csv
from datetime import datetime
import markdown as md   # ğŸ‘ˆ æ–°å¢
import re
load_dotenv()

# æ¨¡å‹é…ç½®
OPENAI_MODEL = os.getenv("EBCS_MODEL", "gpt-5-mini")
EMBED_MODEL = os.getenv("EBCS_EMBED_MODEL", "text-embedding-3-large")

client = OpenAI()

# # Baseline VS è·¯å¾„
# VS_DIR = Path("baseline_from_indexes_vs")
# ENTRIES_PATH = VS_DIR / "baseline_from_idx_entries.json"
# EMB_PATH = VS_DIR / "baseline_from_idx_embeddings.npy"

# -----------------------
# æ—¥å¿— & é—®å· CSV
# -----------------------
LOG_DIR = Path("logs")
LOG_DIR.mkdir(exist_ok=True)
PRE_FILE = LOG_DIR / "pre_survey_baseline.csv"
POST_FILE = LOG_DIR / "post_survey_baseline.csv"
# ğŸ‘‡ æ–°å¢ï¼šèŠå¤©è½®æ¬¡ & snippet ç‚¹å‡»æ—¥å¿—
CHAT_LOG_FILE = LOG_DIR / "chat_turns_baseline.csv"
SNIPPET_LOG_FILE = LOG_DIR / "snippet_clicks_baseline.csv"


from qdrant_client import QdrantClient

# -----------------------
# Qdrant é…ç½®ï¼ˆBaseline ç‰ˆï¼‰
# -----------------------
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
# è¿™ä¸ª collection åå­—ä½ æŒ‰è‡ªå·±åœ¨ Qdrant é‡Œå»ºçš„æ¥æ”¹
BASELINE_COLLECTION = os.getenv("QDRANT_BASELINE_COLLECTION")

@st.cache_resource
def get_qdrant_client():
    return QdrantClient(
        url=QDRANT_URL,
        api_key=QDRANT_API_KEY,
    )


def append_csv_row(path: Path, fieldnames, row_dict):
    """Append one row to a CSV (create header if file doesnâ€™t exist)."""
    file_exists = path.exists()
    with path.open("a", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        if not file_exists:
            writer.writeheader()
        writer.writerow(row_dict)


# -----------------------
# ç™»å½•é€»è¾‘
# -----------------------

def login_page():
    # If already logged in, skip login screen
    if st.session_state.get("user_id"):
        return

    st.write("Please enter your Participant ID and password.")

    # Use stable keys so reruns don't reset unexpectedly
    participant_id = st.text_input(
        "Participant ID",
        value="",
        key="login_participant_id",
    )
    password = st.text_input(
        "Password",
        value="",
        type="password",
        key="login_password",
    )

    if st.button("Start", type="primary"):
        pid = participant_id.strip()
        pw = password.strip()

        # Basic checks
        if not pid or not pw:
            st.warning("You must enter both Participant ID and password.")
            return

        if not pid.isdigit():
            st.error("Participant ID must be a number (e.g., 1, 2, 3â€¦).")
            return

        # Simple mapping: {1: 'user1', 2: 'user2', ...}
        expected_pw = f"user{pid}"

        if pw != expected_pw:
            st.error("Incorrect Participant ID or password.")
            return

        # Successful login
        st.session_state["user_id"] = pid
        st.success(f"Welcome, user{pid}!")
        st.rerun()

# =======
# for the raw snippt, change the url path so that the images can be shown
# =====
def fix_raw_excerpt_md(raw_excerpt_md: str, source_path: str) -> str:
    """
    1ï¼‰æŠŠæœ¬åœ°ç›¸å¯¹ markdown å›¾ç‰‡é“¾æ¥ï¼š
        [alt](images/...xyz)
        ![alt](images/...xyz)
       æ”¹æˆ S3 ä¸Šçš„ç»å¯¹è·¯å¾„ï¼›

    2ï¼‰æŠŠæ‰€æœ‰ markdown é“¾æ¥/å›¾ç‰‡é‡Œçš„ URL é‡Œçš„ç©ºæ ¼æ›¿æ¢æˆ %20ï¼›

    3aï¼‰å¦‚æœå‘ç°å½¢å¦‚  [xxx](https://... .jpg/.png) è¿™ç§â€œæŒ‡å‘å›¾ç‰‡çš„æ™®é€šé“¾æ¥â€ï¼Œ
        è‡ªåŠ¨æ”¹æˆå›¾ç‰‡è¯­æ³•  ![xxx](https://... .jpg/.png)

    3bï¼‰å¦‚æœå‘ç°  alt é‡Œæœ‰å¾ˆå¤šæ¢è¡Œçš„è¶…é•¿å›¾ç‰‡å†™æ³•ï¼Œ
        ç»Ÿä¸€æ”¶ç¼©æˆ  ![image](url)  é¿å… markdown è§£æå¤±è´¥ã€‚
    """

    if not raw_excerpt_md:
        return raw_excerpt_md

    md_text = raw_excerpt_md

    # ---------- 1. å¤„ç†æœ¬åœ°ç›¸å¯¹è·¯å¾„ images/... -> S3 ç»å¯¹è·¯å¾„ ----------
    if source_path:
        import os
        dir_path = os.path.dirname(source_path)

        # Drop "repo..." å‰ç¼€
        m = re.match(r"^repo[^/]*/(.*)$", dir_path)
        if m:
            dir_path_no_repo = m.group(1)
        else:
            dir_path_no_repo = dir_path

        IMG_BASE_URL = "https://delft-public-img.s3.eu-west-1.amazonaws.com/"
        prefix = IMG_BASE_URL + dir_path_no_repo.strip("/") + "/"

        # åŒ¹é… [..](images/...) æˆ– ![..](images/...)
        pattern_local_img = re.compile(r'(!?\[[^\]]*\])\((?:\.?/)?(images/[^)\s]+)\)')

        def _repl_local(m: re.Match) -> str:
            alt = m.group(1)
            rel = m.group(2)
            rel = rel.replace(" ", "%20")
            full_url = prefix + rel
            return f"{alt}({full_url})"

        md_text = pattern_local_img.sub(_repl_local, md_text)

    # ---------- 2. æ‰€æœ‰ markdown URL é‡Œçš„ç©ºæ ¼ -> %20 ----------
    pattern_any_link = re.compile(r'(\]\()([^)]+)\)')

    def _repl_space(m: re.Match) -> str:
        url = m.group(2)
        safe_url = url.replace(" ", "%20")
        return f"]({safe_url})"

    md_text = pattern_any_link.sub(_repl_space, md_text)

    # ---------- 3a. æŒ‡å‘å›¾ç‰‡çš„æ™®é€šé“¾æ¥ -> å›¾ç‰‡è¯­æ³• ----------
    pattern_link_to_img = re.compile(
        r'\[(?P<alt>[^\]]*)\]\((?P<url>https?://[^)\s]+\.(?:png|jpe?g|gif|svg))\)'
    )

    def _repl_link_to_img(m: re.Match) -> str:
        alt = m.group("alt").strip()
        url = m.group("url").strip()
        return f"![{alt}]({url})"

    md_text = pattern_link_to_img.sub(_repl_link_to_img, md_text)

    # ---------- 3b. å¤šè¡Œ alt çš„å›¾ç‰‡ï¼Œç»Ÿä¸€å‹ç¼©æˆ ![image](url) ----------
    # åŒ¹é…ï¼š  ![ ä»»æ„å¤šè¡Œæ–‡å­— ](https://...jpg/png/gif/svg)
    pattern_multiline_img = re.compile(
        r'!\[(?P<alt>.*?)\]\((?P<url>https?://[^)\s]+\.(?:png|jpe?g|gif|svg))\)',
        re.DOTALL,
    )

    def _repl_multiline_img(m: re.Match) -> str:
        url = m.group("url").strip()
        # alt ç›´æ¥ç”¨ä¸€ä¸ªç®€å•çš„å ä½ï¼Œé¿å…æ¢è¡Œ
        return f"![image]({url})"

    md_text = pattern_multiline_img.sub(_repl_multiline_img, md_text)

    return md_text


# -----------------------
# Pre-survey Dialogï¼ˆradio 1â€“7ï¼‰
# -----------------------
# -----------------------
# Pre-survey Dialogï¼ˆradio 1â€“7ï¼‰
# -----------------------
@st.dialog("Before you start: Pre-Survey", dismissible=False, on_dismiss="rerun")
def pre_survey_dialog():
    st.write("Please complete this short pre-survey before using the Thesis Coach system.")

    user_id = st.session_state.get("user_id", None)
    if not user_id:
        st.error("You are not logged in. Please return to the login page.")
        return

    # â€”â€”â€” Initialize pre_tmp (first time only) â€”â€”â€”
    if "pre_tmp" not in st.session_state or not isinstance(st.session_state.pre_tmp, dict):
        st.session_state.pre_tmp = {
            # åŸæœ‰å­—æ®µ
            "prior_exp_llm": 3,
            "prior_trust": 4,
            "topic_clarity": 3,
            "rq_confidence": 3,
            "open_expectations": "",
            # æ–°å¢ï¼šèƒŒæ™¯ + è‡ªæˆ‘æ•ˆèƒ½ + å¯¹æµç¨‹çš„æ€åº¦
            "stage": "",
            "domain_short": "",
            "rubric_familiarity": 2,
            "rq_self_efficacy": 3,
            "method_self_efficacy": 3,
            "rubric_eval_knowledge": 3,
            "procedural_preference": 4,
            "procedural_acceptance": 4,
        }

    pre_tmp = st.session_state.pre_tmp

    # --- 1â€“7 é¢‘ç‡é‡è¡¨ ---
    freq_scale = {
        1: "Very rarely / almost never",
        2: "Rarely",
        3: "Sometimes",
        4: "About half of the time",
        5: "Often",
        6: "Very often",
        7: "Almost always"
    }

    # --- 1â€“7 â€œç¨‹åº¦â€é‡è¡¨ï¼ˆä¿¡ä»»ã€è‡ªä¿¡ã€æ¸…æ™°åº¦ç­‰ï¼‰---
    degree_scale = {
        1: "Very low",
        2: "Low",
        3: "Somewhat low",
        4: "Neutral / in the middle",
        5: "Somewhat high",
        6: "High",
        7: "Very high"
    }

    # --- rubric ç†Ÿæ‚‰åº¦ 1â€“4 é‡è¡¨ ---
    rubric_scale = {
        1: "I have never seen the official IDE thesis rubrics / checklists",
        2: "I have heard of them but never looked at them in detail",
        3: "I have looked at them a few times",
        4: "I often refer to them when working on my thesis"
    }

    # =========================
    #  A. èƒŒæ™¯ä¿¡æ¯
    # =========================
    st.subheader("A. Your current graduation context")

    stage_options = [
        "Not started yet",
        "Exploring topics / ideas",
        "Thesis proposal or pre-proposal",
        "Preparing for green-light",
        "Midterm phase",
        "Final writing / finishing phase",
        "Other / not sure",
    ]
    stage_default = pre_tmp.get("stage", "") or stage_options[0]
    stage = st.selectbox(
        "Which stage are you currently in with your graduation project?",
        options=stage_options,
        index=stage_options.index(stage_default) if stage_default in stage_options else 0,
    )
    st.session_state.pre_tmp["stage"] = stage

    domain_default = pre_tmp.get("domain_short", "")
    domain_short = st.text_input(
        "In one or two short phrases, how would you describe your graduation topic or domain? (e.g., hospital robot collaboration, warehouse teamwork, etc.)",
        value=domain_default,
    )
    st.session_state.pre_tmp["domain_short"] = domain_short

    rubric_familiarity_default = pre_tmp.get("rubric_familiarity", 2)
    rubric_familiarity = st.radio(
        "Before using this system, how familiar are you with the official IDE graduation rubrics or stage checklists?",
        options=list(rubric_scale.keys()),
        # index=max(0, min(3, rubric_familiarity_default - 1)),
        index=None,
        format_func=lambda x: rubric_scale[x],
        horizontal=True,
    )
    st.session_state.pre_tmp["rubric_familiarity"] = rubric_familiarity

    # =========================
    #  B. ä¹‹å‰å¯¹ LLM çš„ç»éªŒ & ä¿¡ä»»
    # =========================
    st.subheader("B. Prior experience with AI tools")

    prior_exp_llm_default = pre_tmp.get("prior_exp_llm", 3)
    prior_exp_llm = st.radio(
        "How often have you previously used large language models (e.g., ChatGPT) for study or academic work?",
        options=list(freq_scale.keys()),
        # index=max(0, min(6, prior_exp_llm_default - 1)),
        index=None,
        format_func=lambda x: freq_scale[x],
        horizontal=True
    )
    st.session_state.pre_tmp["prior_exp_llm"] = prior_exp_llm

    prior_trust_default = pre_tmp.get("prior_trust", 4)
    prior_trust = st.radio(
        "Before using this system, how much do you trust AI-based feedback or supervision tools?",
        options=list(degree_scale.keys()),
        # index=max(0, min(6, prior_trust_default - 1)),
        index=None,
        format_func=lambda x: degree_scale[x],
        horizontal=True
    )
    st.session_state.pre_tmp["prior_trust"] = prior_trust

    # =========================
    #  C. å¯¹è¯¾é¢˜æ¸…æ™°åº¦ & è‡ªæˆ‘æ•ˆèƒ½
    # =========================
    st.subheader("C. Your thesis clarity and confidence")

    topic_clarity_default = pre_tmp.get("topic_clarity", 3)
    topic_clarity = st.radio(
        "How clear are you about your graduation project topic or research direction?",
        options=list(degree_scale.keys()),
        # index=max(0, min(6, topic_clarity_default - 1)),
        index=None,
        format_func=lambda x: degree_scale[x],
        horizontal=True
    )
    st.session_state.pre_tmp["topic_clarity"] = topic_clarity

    rq_confidence_default = pre_tmp.get("rq_confidence", 3)
    rq_confidence = st.radio(
        "How confident are you right now about your research question or thesis plan?",
        options=list(degree_scale.keys()),
        # index=max(0, min(6, rq_confidence_default - 1)),
        index=None,
        format_func=lambda x: degree_scale[x],
        horizontal=True
    )
    st.session_state.pre_tmp["rq_confidence"] = rq_confidence

    rq_self_efficacy_default = pre_tmp.get("rq_self_efficacy", 3)
    rq_self_efficacy = st.radio(
        "Without any special tools, how confident are you that you can formulate a good research question (RQ)?",
        options=list(degree_scale.keys()),
        # index=max(0, min(6, rq_self_efficacy_default - 1)),
        index=None,
        format_func=lambda x: degree_scale[x],
        horizontal=True,
    )
    st.session_state.pre_tmp["rq_self_efficacy"] = rq_self_efficacy

    method_self_efficacy_default = pre_tmp.get("method_self_efficacy", 3)
    method_self_efficacy = st.radio(
        "Without any special tools, how confident are you in choosing suitable methods and measurements to support your RQ?",
        options=list(degree_scale.keys()),
        # index=max(0, min(6, method_self_efficacy_default - 1)),
        index=None,
        format_func=lambda x: degree_scale[x],
        horizontal=True,
    )
    st.session_state.pre_tmp["method_self_efficacy"] = method_self_efficacy

    rubric_eval_knowledge_default = pre_tmp.get("rubric_eval_knowledge", 3)
    rubric_eval_knowledge = st.radio(
        "How well do you think you understand how IDE assessors will judge whether a thesis plan is â€˜readyâ€™ based on the official criteria?",
        options=list(degree_scale.keys()),
        # index=max(0, min(6, rubric_eval_knowledge_default - 1)),
        index=None,
        format_func=lambda x: degree_scale[x],
        horizontal=True,
    )
    st.session_state.pre_tmp["rubric_eval_knowledge"] = rubric_eval_knowledge

    # =========================
    #  D. å¯¹â€œæŒ‰æµç¨‹æ¥â€çš„æ€åº¦ï¼ˆprocedural orientationï¼‰
    # =========================
    st.subheader("D. Your attitude towards structured processes")

    procedural_preference_default = pre_tmp.get("procedural_preference", 4)
    procedural_preference = st.radio(
        "In your study or projects, how much do you prefer having clear steps and checkpoints, instead of full freedom?",
        options=list(degree_scale.keys()),
        # index=max(0, min(6, procedural_preference_default - 1)),
        index=None,
        format_func=lambda x: degree_scale[x],
        horizontal=True,
    )
    st.session_state.pre_tmp["procedural_preference"] = procedural_preference

    procedural_acceptance_default = pre_tmp.get("procedural_acceptance", 4)
    procedural_acceptance = st.radio(
        "If a digital tool requires you to follow a certain process (e.g., read rubrics, check evidence) before continuing, how acceptable is that to you?",
        options=list(degree_scale.keys()),
        # index=max(0, min(6, procedural_acceptance_default - 1)),
        index=None,
        format_func=lambda x: degree_scale[x],
        horizontal=True,
    )
    st.session_state.pre_tmp["procedural_acceptance"] = procedural_acceptance

    # =========================
    #  E. å¼€æ”¾æ€§é—®é¢˜ï¼šå¯¹ç³»ç»Ÿçš„æœŸå¾…
    # =========================
    st.subheader("E. Expectations for the Thesis Coach")

    open_expectations_default = pre_tmp.get("open_expectations", "")
    open_expectations = st.text_area(
        "What do you expect the Thesis Coach to help you with? (optional, you can answer in English or Chinese)",
        open_expectations_default,
    )
    st.session_state.pre_tmp["open_expectations"] = open_expectations

    # â€”â€” Submit â€”â€”
    if st.button("Submit", type="primary"):
        missing = []

        if None in (stage, domain_short, rubric_familiarity,prior_exp_llm,prior_trust,topic_clarity,rq_confidence,
                    rq_self_efficacy,method_self_efficacy,rubric_eval_knowledge,procedural_preference,procedural_acceptance):
            missing.append("Some required fields were not answered.")

        if missing:
            st.error("You must answer all required questions:\n- " + "\n- ".join(missing))
            st.stop()

        st.session_state["pre_survey"] = st.session_state.pre_tmp.copy()
        st.session_state["pre_survey_done"] = True

        row = {
            "timestamp": datetime.utcnow().isoformat(),
            "user_id": user_id,
            # èƒŒæ™¯
            "stage": stage,
            "domain_short": domain_short,
            "rubric_familiarity": rubric_familiarity,
            # LLM & trust
            "prior_exp_llm": prior_exp_llm,
            "prior_trust": prior_trust,
            # clarity & efficacy
            "topic_clarity": topic_clarity,
            "rq_confidence": rq_confidence,
            "rq_self_efficacy": rq_self_efficacy,
            "method_self_efficacy": method_self_efficacy,
            "rubric_eval_knowledge": rubric_eval_knowledge,
            # procedural attitude
            "procedural_preference": procedural_preference,
            "procedural_acceptance": procedural_acceptance,
            # open text
            "open_expectations": open_expectations,
        }
        append_csv_row(PRE_FILE, fieldnames=list(row.keys()), row_dict=row)

        st.success("Thank you! You may now use the system.")
        st.rerun()


def maybe_show_pre_survey():
    if st.session_state.get("pre_survey_done"):
        return
    pre_survey_dialog()


# -----------------------
# Post-survey Dialogï¼ˆradio 1â€“7ï¼‰
# -----------------------
# -----------------------
# Post-survey Dialogï¼ˆradio 1â€“7ï¼‰
# -----------------------
@st.dialog("Post-Survey", dismissible=False, on_dismiss="rerun")
def post_survey_dialog():
    st.write("Please complete this short post-survey after using the Thesis Coach system.")

    user_id = st.session_state.get("user_id", None)
    if not user_id:
        st.error("You are not logged in. Please return to the login page.")
        return

    # â€”â€”â€” Initialize post_tmp (first time only) â€”â€”â€”
    if "post_tmp" not in st.session_state or not isinstance(st.session_state.post_tmp, dict):
        st.session_state.post_tmp = {
            # åŸæœ‰å­—æ®µ
            "perceived_usefulness": 4,
            "perceived_procedural_fairness": 4,
            "perceived_transparency": 4,
            "trust_after": 4,
            "clarity_improved": 4,
            "cognitive_load": 4,
            "satisfaction": 4,
            "open_feedback": "",
            # æ–°å¢ï¼šæ›´ç»†çš„ procedural trust / è¯æ®ä½¿ç”¨ / æ ¡å‡† / å¯ç”¨æ€§ / UI
            "procedural_rules_clarity": 4,
            "procedural_predictability": 4,
            "procedural_voice": 4,
            "evidence_engagement": 4,
            "evidence_cross_check": 4,
            "safety_support": 4,
            "trust_double_check": 4,
            "overtrust_concern": 4,
            "usability_ease": 4,
            "helpful_elements": "",
        }

    post_tmp = st.session_state.post_tmp

    degree_scale = {
        1: "Very low / very negative",
        2: "Low",
        3: "Somewhat low",
        4: "Neutral / in the middle",
        5: "Somewhat high",
        6: "High",
        7: "Very high / very positive"
    }
    demand_scale = {
        1: "Not demanding at all",
        2: "Slightly demanding",
        3: "Somewhat demanding",
        4: "Moderately demanding",
        5: "Quite demanding",
        6: "Very demanding",
        7: "Extremely demanding"
    }

    def radio_1to7(label: str, field: str, scale: Dict[int, str]) -> int:
        default_val = post_tmp.get(field, 4)
        return st.radio(
            label,
            options=list(scale.keys()),
            # index=max(0, min(6, default_val - 1)),
            index=None,
            format_func=lambda x: scale[x],
            horizontal=True
        )

    # =========================
    #  A. Overall usefulness, clarity, trust, satisfaction
    # =========================
    st.subheader("A. Overall experience")

    perceived_usefulness = radio_1to7(
        "Overall, how useful was the Thesis Coach for your current thesis task?",
        "perceived_usefulness",
        degree_scale,
    )
    st.session_state.post_tmp["perceived_usefulness"] = perceived_usefulness

    clarity_improved = radio_1to7(
        "Did the session help you become clearer about your thesis problem, RQ, or next steps?",
        "clarity_improved",
        degree_scale,
    )
    st.session_state.post_tmp["clarity_improved"] = clarity_improved

    trust_after = radio_1to7(
        "After using this system, how much do you trust its feedback and guidance?",
        "trust_after",
        degree_scale,
    )
    st.session_state.post_tmp["trust_after"] = trust_after

    satisfaction = radio_1to7(
        "Overall, how satisfied are you with this interaction with the Thesis Coach?",
        "satisfaction",
        degree_scale,
    )
    st.session_state.post_tmp["satisfaction"] = satisfaction

    usability_ease = radio_1to7(
        "Overall, how easy or difficult was it to use the system to complete this task?",
        "usability_ease",
        degree_scale,
    )
    st.session_state.post_tmp["usability_ease"] = usability_ease

    cognitive_load = radio_1to7(
        "How mentally demanding did you find the interaction with the system?",
        "cognitive_load",
        demand_scale,
    )
    st.session_state.post_tmp["cognitive_load"] = cognitive_load

    # =========================
    #  B. Procedural fairness & transparency (æ›´ç»†æ‹†åˆ†)
    # =========================
    st.subheader("B. Procedural fairness and transparency")

    perceived_procedural_fairness = radio_1to7(
        "Did the process of getting feedback from the system feel systematic and fair (e.g., based on clear criteria rather than arbitrary answers)?",
        "perceived_procedural_fairness",
        degree_scale,
    )
    perceived_transparency = radio_1to7(
        "How transparent did the system feel about *why* it gave particular suggestions (e.g., showing rubrics or precedents)?",
        "perceived_transparency",
        degree_scale,
    )

    procedural_rules_clarity = radio_1to7(
        "During this session, how clear did it feel that the system was following a consistent set of rules or criteria?",
        "procedural_rules_clarity",
        degree_scale,
    )

    procedural_predictability = radio_1to7(
        "How predictable did the systemâ€™s next steps feel (e.g., what it would ask you to do next)?",
        "procedural_predictability",
        degree_scale,
    )

    procedural_voice = radio_1to7(
        "When you did not fully agree with the systemâ€™s suggestions, did you still feel you had room to express your own ideas or choose another path?",
        "procedural_voice",
        degree_scale,
    )

    # =========================
    #  C. Evidence use and perceived safety
    # =========================
    st.subheader("C. Evidence use and perceived safety")

    evidence_engagement = radio_1to7(
        "This system encouraged me to actually open and read the sources or snippets it provided (instead of just trusting the answer).",
        "evidence_engagement",
        degree_scale,
    )

    evidence_cross_check = radio_1to7(
        "Before making decisions, I usually checked whether at least one or two snippets really supported the systemâ€™s suggestions.",
        "evidence_cross_check",
        degree_scale,
    )

    safety_support = radio_1to7(
        "In this task, I felt that the system helped me avoid decisions that might be risky or weak for my thesis.",
        "safety_support",
        degree_scale,
    )

    # =========================
    #  D. Trust calibrationï¼ˆä¸è¿‡åº¦ä¾èµ– vs åˆç†æ£€æŸ¥ï¼‰
    # =========================
    st.subheader("D. Trust calibration")

    trust_double_check = radio_1to7(
        "Even when the system sounded confident, I still used my own judgement or other information to double-check important suggestions.",
        "trust_double_check",
        degree_scale,
    )

    overtrust_concern = radio_1to7(
        "At some moments in this task, I felt that I might be relying too much on the system.",
        "overtrust_concern",
        degree_scale,
    )


    # =========================
    #  E. Specific interface elements
    # =========================
    st.subheader("E. Interface elements")

    helpful_elements_options = [
        "The separate sources / snippet buttons",
        "The right-hand snippet panel with raw text",
        "Seeing titles and similarity scores of retrieved snippets",
        "The general chat interface",
        "Other elements (please describe in the text box below)",
        "None of the above were particularly helpful",
    ]
    # Load selection safely from session_state (must be list, not string)
    if isinstance(post_tmp.get("helpful_elements"), list):
        default_list = post_tmp["helpful_elements"]
    else:
        default_list = []

    helpful_elements_selected = st.multiselect(
        "Which interface elements of the Thesis Coach did you personally find especially helpful in this session? (you can select multiple)",
        options=helpful_elements_options,
        default=default_list,
    )

    open_feedback_default = post_tmp.get("open_feedback (optional)", "")
    open_feedback = st.text_area(
        "If you have any comments about what worked well or what felt problematic (e.g., fairness, clarity, missing support), please write them here.",
        open_feedback_default,
    )

    # â€”â€” Submit â€”â€”
    if st.button("Submit", type="primary"):
        missing = []

        if None in (perceived_procedural_fairness, perceived_transparency,
                    procedural_rules_clarity,procedural_predictability,procedural_voice,evidence_engagement,
                    evidence_cross_check,safety_support,trust_double_check,overtrust_concern):
            missing.append("Some required fields were not answered.")

        if missing:
            st.error("You must answer all required questions:\n- " + "\n- ".join(missing))
            st.stop()

        # DO NOT write back immediately â€” only write back when submit
        st.session_state.post_tmp["helpful_elements"] = helpful_elements_selected
        st.session_state.post_tmp["open_feedback"] = open_feedback
        st.session_state.post_tmp["perceived_procedural_fairness"] = perceived_procedural_fairness
        st.session_state.post_tmp["perceived_transparency"] = perceived_transparency
        st.session_state.post_tmp["procedural_rules_clarity"] = procedural_rules_clarity
        st.session_state.post_tmp["procedural_predictability"] = procedural_predictability
        st.session_state.post_tmp["procedural_voice"] = procedural_voice
        st.session_state.post_tmp["evidence_engagement"] = evidence_engagement
        st.session_state.post_tmp["evidence_cross_check"] = evidence_cross_check
        st.session_state.post_tmp["safety_support"] = safety_support
        st.session_state.post_tmp["trust_double_check"] = trust_double_check
        st.session_state.post_tmp["overtrust_concern"] = overtrust_concern
        st.session_state["post_survey"] = st.session_state.post_tmp.copy()
        st.session_state["post_survey_done"] = True

        row = {
            "timestamp": datetime.utcnow().isoformat(),
            "user_id": user_id,
            # overall
            "perceived_usefulness": perceived_usefulness,
            "clarity_improved": clarity_improved,
            "trust_after": trust_after,
            "satisfaction": satisfaction,
            "usability_ease": usability_ease,
            "cognitive_load": cognitive_load,
            # procedural trust / transparency
            "perceived_procedural_fairness": perceived_procedural_fairness,
            "perceived_transparency": perceived_transparency,
            "procedural_rules_clarity": procedural_rules_clarity,
            "procedural_predictability": procedural_predictability,
            "procedural_voice": procedural_voice,
            # evidence & safety
            "evidence_engagement": evidence_engagement,
            "evidence_cross_check": evidence_cross_check,
            "safety_support": safety_support,
            # calibration
            "trust_double_check": trust_double_check,
            "overtrust_concern": overtrust_concern,
            # UI elements & open feedback
            "helpful_elements": "; ".join(helpful_elements_selected),
            "open_feedback": open_feedback,
        }
        append_csv_row(POST_FILE, fieldnames=list(row.keys()), row_dict=row)

        st.success("Thank you for your feedback!")
        st.rerun()

# -----------------------
# å·¥å…·å‡½æ•°ï¼ˆå‘é‡æ£€ç´¢ï¼‰
# -----------------------
# def load_vector_store():
#     if not ENTRIES_PATH.exists() or not EMB_PATH.exists():
#         raise FileNotFoundError(
#             f"Vector store not found. Please run build_baseline_from_indexes.py first.\n"
#             f"Expected files:\n  {ENTRIES_PATH}\n  {EMB_PATH}"
#         )
#     entries = json.loads(ENTRIES_PATH.read_text(encoding="utf-8"))
#     emb_matrix = np.load(EMB_PATH)
#     if emb_matrix.dtype != np.float32:
#         emb_matrix = emb_matrix.astype("float32")
#     return entries, emb_matrix


# @st.cache_resource
# def get_vs_cached():
#     return load_vector_store()


def embed_text(text: str) -> np.ndarray:
    resp = client.embeddings.create(
        model=EMBED_MODEL,
        input=[text],
    )
    return np.array(resp.data[0].embedding, dtype="float32")

def cosine_sim_matrix(matrix: np.ndarray, query_vec: np.ndarray) -> np.ndarray:
    denom = (np.linalg.norm(matrix, axis=1) * np.linalg.norm(query_vec) + 1e-9)
    return (matrix @ query_vec) / denom

def retrieve_top_k(
    query: str,
    top_k: int = 6,
) -> List[Dict[str, Any]]:
    """
    åœ¨ Qdrant çš„ BASELINE_COLLECTION é‡Œåšå‘é‡æœç´¢ï¼Œ
    è¿”å›ç»“æ„å°½é‡ä¿æŒå’ŒåŸæ¥ entries+emb_matrix ç‰ˆæœ¬ä¸€è‡´ã€‚
    """
    q_vec = embed_text(query)
    client_q = get_qdrant_client()

    hits = client_q.search(
        collection_name=BASELINE_COLLECTION,
        query_vector=q_vec,
        limit=top_k,
        with_payload=True,
    )

    results: List[Dict[str, Any]] = []
    for rank, h in enumerate(hits, start=1):
        p = h.payload or {}
        # å…¼å®¹ä¸åŒ payload å‘½å
        results.append(
            {
                "rank": rank,
                "score": float(h.score or 0.0),
                # åŸ baseline entries é‡Œæ˜¯ "id"ï¼›å¦‚æœä½ å¯¼å…¥ Qdrant æ—¶ç”¨çš„æ˜¯ "raw_id"ï¼Œè¿™é‡Œå…œåº•ä¸€ä¸‹
                "id": p.get("id") or p.get("raw_id") or h.id,
                "source_type": p.get("source_type"),
                "doc_title": p.get("doc_title"),
                # baseline UI ä¸‹é¢ä¼šæ‹¿ source_id å»ä¿®å›¾ç‰‡é“¾æ¥ï¼Œæ‰€ä»¥è¿™é‡Œä¿ç•™
                "source_id": p.get("source_id") or p.get("source_path") or "",
                "source_path": p.get("source_path"),
                # æ–‡æœ¬å­—æ®µï¼šä½ åœ¨ Qdrant é‡Œå¯ä»¥å« "text"ã€"source_chunk_md" æˆ– "raw_excerpt_md"
                "text": p.get("text")
                        or p.get("source_chunk_md")
                        or p.get("raw_excerpt_md")
                        or "",
            }
        )
    return results

def call_llm_with_context(
    question: str,
    retrieved_chunks: List[Dict[str, Any]],
) -> str:
    context_blocks = []
    for r in retrieved_chunks:
        src = r["source_type"]
        doc = r.get("doc_title") or r.get("source_id") or "(unknown)"
        header = f"[{r['rank']}] ({src}) {doc}"
        block = f"{header}\n{r['text']}"
        context_blocks.append(block)
    context_text = "\n\n---\n\n".join(context_blocks)
    system_prompt = (
        "You are a simple RAG-based thesis coach for IDE MSc graduation projects.\n"
        "You must answer the student's question ONLY using the provided context snippets, which come from official rubrics and past IDE master theses.\n"
        "If the answer is not clearly supported by the context, say that you cannot be sure "
        "and explain what additional information or documents the student should check.\n"
        "Be concrete and concise. You may answer in the same language as the question (Chinese/English)."
    )
    user_prompt = (
        "Student question:\n"
        f"{question}\n\n"
        "Relevant context snippets:\n"
       "---------------------------------\n"
        f"{context_text}\n"
        "---------------------------------\n"
        "Now answer the student's question based on these snippets."
    )

    resp = client.responses.create(
        model=OPENAI_MODEL,
        input=[
            {
                "role": "system",
                "content": [{"type": "input_text", "text": system_prompt}],
            },
            {
                "role": "user",
                "content": [{"type": "input_text", "text": user_prompt}],
            },
        ],
    )

    if hasattr(resp, "output_text"):
        return resp.output_text.strip()

    texts = []
    for o in resp.output:
        for c in o.content:
            if getattr(c, "type", "") == "output_text":
                texts.append(c.text)
    return "".join(texts).strip()


# -----------------------
# çŠ¶æ€ç®¡ç† & UI
# -----------------------

def init_state():
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "retrievals" not in st.session_state:
        st.session_state.retrievals = []
    if "busy" not in st.session_state:
        st.session_state.busy = False
    # æ–°å¢ï¼šå³ä¾§ snippet é¢æ¿æ§åˆ¶
    if "show_snippet_panel" not in st.session_state:
        st.session_state.show_snippet_panel = False
    if "selected_snippet_rank" not in st.session_state:
        st.session_state.selected_snippet_rank = None
        # ğŸ‘‡ æ–°å¢ï¼šæœ¬ session å†…ç¬¬å‡ è½®é—®ç­”ï¼ˆ0,1,2,...ï¼‰
    if "turn_counter" not in st.session_state:
        st.session_state.turn_counter = 0

def log_snippet_click(user_id: str, turn_index: int, snippet: Dict[str, Any], action: str):
    """
    è®°å½•æ¯æ¬¡ç‚¹å‡» snippetX çš„è¡Œä¸ºï¼š
    - user_id: å½“å‰ç”¨æˆ·
    - turn_index: ç¬¬å‡ è½®é—®ç­”
    - snippet: retrieve_top_k è¿”å›çš„é‚£ä¸€æ¡ dict
    - action: 'show' or 'hide'
    """
    try:
        row = {
            "timestamp_click": datetime.utcnow().isoformat(),
            "user_id": user_id,
            "turn_index": turn_index,
            "action": action,  # show / hide
            "rank": snippet.get("rank"),
            "snippet_id": snippet.get("id"),
            "source_type": snippet.get("source_type"),
            "score": snippet.get("score"),
            "doc_title": snippet.get("doc_title") or snippet.get("source_id") or "",
        }
        append_csv_row(SNIPPET_LOG_FILE, fieldnames=list(row.keys()), row_dict=row)
    except Exception as e:
        print("Failed to log snippet click:", e)


def show_intro_banner():
    """Show a one-time intro window explaining how to ask the coach."""
    if "show_intro" not in st.session_state:
        st.session_state.show_intro = True

    if not st.session_state.show_intro:
        return

    with st.container():
        st.markdown(
            """
<div style="
    border-radius: 16px;
    padding: 1rem 1.2rem;
    margin-bottom: 1rem;
    border: 1px solid #4b5563;
">
<h3 style="margin-top:0;">How to ask the Thesis Coach</h3>

To get **fast, evidence-based answers** (without extra clarification), try to include:

1. **Domain / topic** â€“ what youâ€™re working on (system, context, problem).
2. **Users / stakeholders** â€“ who it is for.
3. **Key metrics** â€“ 1â€“2 things you want to improve or evaluate (e.g., usability, adoption, workload).
4. **Stage** *(optional but helpful)* â€“ proposal / greenlight / midterm / final / defense.
5. **Draft / method** *(when relevant)* â€“ say if you already have an RQ draft, outline, or planned method.
---
#### ğŸ‘ Good question examples
**Example 1 â€“ proposal / exploration**
> Iâ€™m designing an AR interface to guide warehouse pickers.
> Main users are novice pickers in large e-commerce warehouses.
> I mainly care about task completion time and error rate.
> Iâ€™m in the proposal stage with a rough RQ draft.
> Can you help me improve the research question and check if it fits the IDE proposal rubric?

**Example 2 â€“ greenlight / checklist**
> Iâ€™m preparing my green-light plan for a mental-health chatbot for university students.
> Users: Dutch masterâ€™s students experiencing study stress.
> Metrics: engagement (return visits) and perceived support.
> I have a draft method (diary study + interviews).
> Can you use the green-light checklist to tell me what is missing?

**Example 3 â€“ precedents**
> Iâ€™m working on a decision-support dashboard for ICU nurses.
> Users are experienced nurses; I want to evaluate situation awareness and workload.
> I plan a within-subjects lab study.
> Can you show me IDE thesis precedents with similar methods and metrics?
---
#### ğŸ‘ Bad question examples (and why theyâ€™re bad)
**Bad 1** âŒ No domain, no users, no metrics â†’ the coach can only ask you a follow-up.
> I need help starting my thesis.

**Bad 2** âŒ Domain too vague, no users, no metrics, no stage.
> Iâ€™m doing something with sustainability. What should I do next?

**Bad 3** âŒ No context: we donâ€™t know which stage youâ€™re in, what your topic is, or what â€œfixâ€ means.
> Can you fix my thesis?
-----
You can think of it as a template:
> â€œIâ€™m working on **[domain]** for **[users]**.
> I mainly care about **[metric 1]** and **[metric 2]**, and Iâ€™m at the **[stage]** stage.
> I currently have **[draft / method / no draft yet]**.
> **Can you help me with [X]?**â€
</div>
            """,
            unsafe_allow_html=True,
        )
        # cols = st.columns([1, 0.2])
        # with cols[0]:
        if st.button("Got it", key="intro_dismiss", use_container_width=True):
            st.session_state.show_intro = False
            st.rerun()
def toggle_snippet_panel(rank: int):
    prev = st.session_state.get("selected_snippet_rank")
    showing = st.session_state.get("show_snippet_panel", False)
    if showing and prev == rank:
        st.session_state.show_snippet_panel = False
        st.session_state.selected_snippet_rank = None
    else:
        st.session_state.show_snippet_panel = True
        st.session_state.selected_snippet_rank = rank


def main():
    st.set_page_config(page_title="Baseline RAG Thesis Coach", layout="wide")
    st.title("Baseline A Â· Simple RAG Thesis Coach")
    st.markdown("""
            <style>
        /* Target Streamlit Dialog container */
            div[role="dialog"][aria-label="dialog"] {
        width: 90% !important;           /* or 800px / 100rem / etc */
        max-width:1300px;
        border-radius: 12px !important;
        padding: 0 !important;
        margin: 0 auto !important;       /* center horizontally */
    }

            </style>
            """, unsafe_allow_html=True)
    if "user_id" not in st.session_state:
        st.session_state["user_id"] = None

    login_page()
    if not st.session_state.get("user_id"):
        return

    maybe_show_pre_survey()
    init_state()

    # try:
    #     entries, emb_matrix = get_vs_cached()
    # except FileNotFoundError as e:
    #     st.error(str(e))
    #     st.stop()

    # â¬‡ï¸ Show one-time intro popup/banner
    show_intro_banner()
    # åªæœ‰åœ¨ç‚¹å‡» â€œGot itâ€ åï¼ˆ= show_intro=Falseï¼‰æ‰æ˜¾ç¤ºèŠå¤©æœºå™¨äºº + evidence vault
    if not st.session_state.show_intro:
        # æ ¹æ®æ˜¯å¦éœ€è¦ evidence é¢æ¿å†³å®šå¸ƒå±€
        if st.session_state.get("show_snippet_panel", False):
            col_chat, col_ctx = st.columns([2.2, 1.8])
        else:
            col_chat, = st.columns([1])
            col_ctx = None

        # ---------- å·¦ä¾§ï¼šèŠå¤© ----------
        with col_chat:
            st.caption("Example question: Iâ€™m designing an AR interface to guide warehouse pickers. Main users are novice pickers in large e-commerce warehouses. I mainly care about task completion time and error rate. Iâ€™m in the proposal stage with a rough RQ draft. Can you help me improve the research question and check if it fits the IDE proposal rubric?")
            st.caption("Example question: Iâ€™m preparing my green-light plan for a mental-health chatbot for university students.Users: Dutch masterâ€™s students experiencing study stress.Metrics: engagement (return visits) and perceived support.I have a draft method (diary study + interviews).Can you use the green-light checklist to tell me what is missing?")
            # å±•ç¤ºå†å²å¯¹è¯
            for i, msg in enumerate(st.session_state.messages):
                with st.chat_message(msg["role"]):
                    st.markdown(msg["content"])

            # advice æ˜¯å¦å·²ç»™å‡º
            assistant_msgs = [m for m in st.session_state.messages if m["role"] == "assistant"]
            advice_given = len(assistant_msgs) > 0

            # å–æœ¬è½®æ£€ç´¢ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            latest_retrieval = st.session_state.retrievals[-1] if st.session_state.retrievals else []

            # åœ¨æœ€åä¸€æ¡ assistant æ¶ˆæ¯ååŠ â€œSources: snippet1, ...â€
            if advice_given and latest_retrieval:
                st.markdown("**Sources:**", unsafe_allow_html=True)
                st.caption("Click the snippet to show the raw text at the top. Double click to hide.")
                cols = st.columns(len(latest_retrieval))
                for idx, r in enumerate(latest_retrieval):
                    label = f"snippet{r['rank']}"
                    with cols[idx]:
                        is_selected = (
                                st.session_state.get("selected_snippet_rank") == r["rank"]
                                and st.session_state.get("show_snippet_panel")
                        )

                        clicked = st.button(
                            label,
                            key=f"snippet-btn-{r['rank']}",
                            type=("primary" if is_selected else "secondary"),
                        )

                        if clicked:
                            # ç‚¹å‡»ä¹‹å‰çš„çŠ¶æ€
                            prev_rank = st.session_state.get("selected_snippet_rank")
                            prev_show = st.session_state.get("show_snippet_panel", False)

                            # è¿™æ¬¡ç‚¹å‡»çš„ç»“æœæ˜¯ show è¿˜æ˜¯ hideï¼Ÿ
                            if prev_show and prev_rank == r["rank"]:
                                action = "hide"
                            else:
                                action = "show"

                            # å†™ç‚¹å‡»æ—¥å¿—
                            user_id = st.session_state.get("user_id") or ""
                            turn_idx = max(0, st.session_state.get("turn_counter", 1) - 1)
                            # turn_counter åœ¨ç”Ÿæˆç­”æ¡ˆå +1ï¼Œè¿™é‡Œé€šå¸¸æƒ³ç»‘å®šåˆ°â€œä¸Šä¸€è½®å›ç­”â€
                            log_snippet_click(user_id, turn_idx, r, action)

                            # æ›´æ–° UI çŠ¶æ€
                            toggle_snippet_panel(r["rank"])
                            st.rerun()

            # chat input / post-survey æ§åˆ¶
            user_input = None
            if st.session_state.busy:
                st.info("The coach is thinkingâ€¦")
                st.rerun()
            else:
                if advice_given:
                    st.info("The advice is given for this round.")
                    if not st.session_state.get("post_survey_done", False):
                        if st.button("End this conversation & fill post-survey"):
                            post_survey_dialog()
                    else:
                        st.success("The post-survey is finished, thanks for participating!")
                else:
                    user_input = st.chat_input("ask your questions")

            # ä»…åœ¨ç¬¬ä¸€æ¬¡æé—®æ—¶ç”Ÿæˆå›ç­”
            if user_input and not advice_given:
                st.session_state.busy = True
                # è®°å½•é—®é¢˜æ—¶é—´æˆ³
                ts_q = datetime.utcnow().isoformat()
                # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ° session
                st.session_state.messages.append({"role": "user", "content": user_input})

                with st.spinner("Retrieving relevant snippets and generating an answerâ€¦"):
                    # è½®æ¬¡å·ï¼ˆå…ˆç¼“å­˜ï¼Œåé¢å†™æ—¥å¿—ç”¨ï¼‰
                    turn_idx = st.session_state.turn_counter
                    retrieved = retrieve_top_k(
                        query=user_input,
                        top_k=6,
                    )
                    st.session_state.retrievals.append(retrieved)

                    answer = call_llm_with_context(
                        question=user_input,
                        retrieved_chunks=retrieved,
                    )
                    # å›ç­”æ—¶é—´æˆ³
                    ts_a = datetime.utcnow().isoformat()
                    # -------- å†™èŠå¤©æ—¥å¿—åˆ° CSV --------
                    try:
                        user_id = st.session_state.get("user_id") or ""
                        row = {
                            "user_id": user_id,
                            "turn_index": turn_idx,
                            "timestamp_question": ts_q,
                            "timestamp_answer": ts_a,
                            "question": user_input,
                            "answer": answer,
                            # æŠŠæœ¬è½®æ‰€æœ‰ snippet çš„å…³é”®ä¿¡æ¯æ‰“å¹³æˆå­—ç¬¦ä¸²
                            "retrieved_ids": ";".join(str(r.get("id", "")) for r in retrieved),
                            "retrieved_ranks": ";".join(str(r.get("rank", "")) for r in retrieved),
                            "retrieved_scores": ";".join(f"{r.get('score', 0):.4f}" for r in retrieved),
                            "retrieved_source_types": ";".join(str(r.get("source_type", "")) for r in retrieved),
                            "retrieved_doc_titles": ";".join(
                                (r.get("doc_title") or r.get("source_id") or "").replace(";", ",")
                                for r in retrieved
                            ),
                        }
                        append_csv_row(CHAT_LOG_FILE, fieldnames=list(row.keys()), row_dict=row)
                    except Exception as e:
                        # ä¸è¦æ‰“æ–­ç”¨æˆ·æµç¨‹ï¼Œå¤±è´¥å°±é™é»˜å¿½ç•¥æˆ–ç®€å• print
                        print("Failed to log chat turn:", e)

                # è½®æ¬¡ +1
                st.session_state.turn_counter += 1
                st.session_state.messages.append({"role": "assistant", "content": answer})
                st.session_state.busy = False
                st.rerun()

        # ---------- å³ä¾§ï¼šå•æ¡ Retrieved snippet ----------
        if col_ctx is not None:
            with col_ctx:
                st.subheader("Retrieved snippet (this round)")

                latest = st.session_state.retrievals[-1] if st.session_state.retrievals else []
                selected_rank = st.session_state.get("selected_snippet_rank")

                if not latest or selected_rank is None:
                    st.caption("Click a source button below the advice to inspect a snippet.")
                else:
                    # æ‰¾åˆ°è¢«é€‰ä¸­çš„ snippet
                    snippet = None
                    for r in latest:
                        if r["rank"] == selected_rank:
                            snippet = r
                            break

                    if snippet is None:
                        st.caption("Snippet not found.")
                    else:
                        # st.write("DEBUG meta for", snippet)
                        src = snippet["source_type"]
                        doc = snippet.get("doc_title") or snippet.get("source_id") or "(unknown source)"
                        st.markdown(
                            f"**[{snippet['rank']}] ({src}) {doc}**  \n"
                            f"`similarity score = {snippet['score']:.3f}`"
                        )
                        st.caption(
                            "In the raw text snippet below, you can scroll down in the box to see the whole content.")
                        # ä¿®å¤ markdown ä¸­çš„å›¾ç‰‡é“¾æ¥
                        fixed_md = fix_raw_excerpt_md(snippet["text"], snippet.get("source_id") or "")

                        # å°† markdown è½¬æˆ HTML
                        snippet_html = md.markdown(fixed_md)

                        st.markdown(
                            f"""
                    <div style="
                        border: 1px solid #e5e7eb;
                        border-radius: 8px;
                        padding: 0.6rem 0.8rem;
                        height: 30rem;              /* å›ºå®šé«˜åº¦ */
                        overflow-y: auto;           /* ç«–å‘æ»šåŠ¨ */
                        overflow-x: hidden;
                        width: 100%;                /* å æ»¡å³ä¾§åˆ—å®½åº¦ */
                        box-sizing: border-box;
                    ">
                    {snippet_html}
                    </div>
                            """,
                            unsafe_allow_html=True,
                        )

                # st.markdown("---")
                # st.caption(
                #     "Baseline A = simple vector search over raw markdown chunks "
                #     "(`source_chunk_md`), no Stage Ã— Mode Ã— Gap routing, no tags."
                # )

if __name__ == "__main__":
    main()
